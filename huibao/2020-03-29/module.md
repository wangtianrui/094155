





# 2020-03-29 汇报

> 本汇报分为三个大点
>
> 1、已做的事儿
>
> 2、打算做什么
>
> 3、想问的问题

## 本周已做的事儿

* ###  参阅多种文献，对音节分割结果进行了判定

  * R-value        An improved speech segmentation quality measure: the r-value. in Interspeech, 2009

    * 判定了预测边界的准确率和超预测率（比如一共label有5个边界，但是预测出了6个，那么就多预测了，会纳入判定）

      ![](https://s1.ax1x.com/2020/03/29/GEoCHe.png)

      其中HR是边界预测正确的数量占label边界总数量的比例 * 100  （100为满分）

      OS是预测出的边界数与label边界数的比值

      文献中还提到，判定准确率时判定区域大小设计的问题，判定区域越大正确率自然就会越大，文中提到普遍的音素分割的区域选择是±20ms，通过计算平均占整体音长的45%![](https://s1.ax1x.com/2020/03/29/GET2zq.png)

      所以我也按相同比例进行转换，因为文献是做的音素分割，我们音节分割，音节数比音素少，所以按比例45%计算。我选择的区域大小为：

      ### 					$region = \frac{250*0.45}{syllable num}$

      ​							2.5s -> 250帧，一帧10ms

      通过统计，数据集中每2.5s平均音节个数为5.8

      所以region的大小我选择为200ms  —>  20帧  ， ±10帧 

      根据数据集分析，平均每个音节持续时长为22.750633601879827帧->227.5ms，所以相当于选择了前后近半个音节作为正确区域（和上述文献一样）

    * ![](https://s1.ax1x.com/2020/03/29/GEo0UJ.png)

      这是2017年8月份的一篇文献利用R-value对多种网络的评估结果（也是用的±20ms作为区域，占总区域的45%）

    * #### 最终我们的模型的测试结果为

      ```
      R-value : 0.848454416884475
      HR : 82.7358510352696
      OS : -4.1905349172791
      每个音节平均误差在 ±2.324858757062147帧  -> ±23.25ms
      ```

    * 然后我参考另一篇2018年arxiv文献，使用常用的F1score进行分析

      参考文献中他们对歌声音节划分的F1-score为（当然，数据集不同准确率肯定也会有所影响，只是提供一个参考）

      ![](https://s1.ax1x.com/2020/03/29/GEq6BV.png)

      我们的模型的    F1-Score：0.830829

* ### 整理了所有非抽象特征的提取，并将检测方法类似的进行了合并

  ```
  生理
  - 年龄
    - MFCC
  - 性别
    - MFCC
  - 清脆度
    - MFCC
  
  发音调控
  - 发音干净程度
    - MFCC
  - 相邻字音黏着度
    - MFCC
  - 平均音高
    - pitch   
    - (中位数 + 均值) / 2
  - 音高变化
    - pitch   
    - 方差
  - 语调圆润度
    - MFCC
  - 停顿频率
    - Fbank + pitch
  - 语速
    - Fbank + pitch
  - 节奏稳定性
    - （各音节发音速度的方差）
  ```

* ### 针对都是利用MFCC进行检测的特征进行了模型的训练

```
测试集平均误差：（均为最大值为7的小数）
    "年龄感",      "性别感",     "清脆度",     "发音黏着程度"   "语调切换的圆润度"
 0.70065402681 1.13084420650 1.15585780881  1.0075982218    0.92381925050
```

* ### 尝试通过上述已能够提取的特征去预测抽象特征

* 分别对应的误差为：

  ```
  '低缓', 2.45246577 
  '冷漠', 2.47471934 
  '冷艳',2.0177001  
  '单纯', 1.9603087  
  '孱弱',2.10634169 
  '尖细', 1.51284728 
  '戏谑', 0.9030168  
  '有力', 2.30114503 
  '木楞', 1.13594644 
  '正义',1.74873431 
  '沧桑',0.90660615 
  '活力',2.10600048 
  '清爽',1.91771372 
  '温柔',1.52837223 
  '滑稽',0.52834271 
  '激情',2.0196613  
  '神圣',0.54276545 
  '轻佻',2.16126159  
  '高傲',2.7257392  
  '成熟'1.72890164
  ```

  可以看出部分误差较小的是原本数据集中相关标签不均匀造成的。其余的都在1.7以上，相对之前我们做的1.0左右误差的来讲要大一点。但是也能突显出前面非抽象特征与后面抽象特征有一定的关联性。为我们后面的层级模型打下基础。


## 下周计划

- 尝试将多个模型串联起来
- 尝试将非抽象特征动态地加入到模型中，去预测抽象特征

## 想问的问题

- 无