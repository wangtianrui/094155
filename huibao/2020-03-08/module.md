# 2020-03-08 汇报

> 本汇报分为三个大点
>
> 1、已做的事儿
>
> 2、打算做什么
>
> 3、想问的问题

## 本周已做的事儿

* ###  利用praat工具尝试提取了音高、mel倒谱等特征

* ### 阅读praat源码，利用python工具实现对音高的提取

  * 横轴是时间，纵轴是频率，后面均做了合理过滤，将范围限制在80hz~500hz

  ![](https://s2.ax1x.com/2020/03/08/3xmVvF.png)

* ### 描述模型中，与音高有关的描述维度的获取

  以下是我的获取思路

  ```
  平均音高 = (中位数 + 均值) / 2         #防止极端值、误差值过度干扰均值
  音高变化: 方差     #直接用最高值减最低值，得不到变化的频率之类的，方差能较好地将变化频率和范围融合
  音高变换的圆润度: 变化点与周围两点误差绝对值的均值  #理论上是求导数，但由于点的离散性，导数无法合理估计。所以用的  
  ```

* ### 对于之前实现的音素分割算法改进为了音节分割

  * #### 将音素改为了音节

  * #### 融入音高特征、结合fbank进行处理

  * #### 发现普遍方法的问题：

    * 一般来说（目前我查阅的资料）。大多数因素/音节分割都将模型分成了2个。一个预测开始的位置，一个预测持续时长。这样模型会出现一个脱节的现象，训练比较麻烦而且用的时候速度较慢。
    * 需要预选框，会造成较大的资源占用。

  * #### 将之前的思路改进成了整体回归（速度效率提升高、不用做预选窗格、能够更有效地预测音节的结束位置）

    ![](https://s2.ax1x.com/2020/03/08/3xMDoj.png)

    图中横轴是时间，单位是s，橘色的点是标签，每一个突起落下就是一个完整的音节。蓝色的点是预测出来的标签。由于我们是做音节分割，所以只需要关注起落的这么一个周期。一个起落对应了一个音节。可以看到效果还算不错。

    本方法只需要训练一个模型。目前感觉在理论上，我这个思路只适合处理短时音频（因为如果音节过多，会出现无法拟合的现象，所以最好是将音频分成很多个3s的段来进行处理）

    如果想要提升拟合能力（能一次性拟合更多的音节），我感觉需要提升后面连接层的复杂度。目前电脑资源有限，无法尝试。

* #### 描述模型中，能够用音节分割得到的描述维度：相邻字发音黏着程度、停顿频次、语速控制、节奏的稳定性，以下是我初步的获取思路

  ```
  相邻字发音黏着程度: 发音平均长度 - 间隔
  停顿频次：音节之间间隔次数/时间
  语速控制:音节发音时间的均值
  节奏的稳定性：-（各音节发音速度的方差）
  ```

* ### 阅读韩老师的《语音信号处理》


## 下周计划

- 继续阅读资料书
- 着手合并模型

## 想问的问题

- 无

想个办法把边界揉进fbank