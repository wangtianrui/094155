# 2020-03-22 汇报

> 本汇报分为三个大点
>
> 1、已做的事儿
>
> 2、打算做什么
>
> 3、想问的问题

## 本周已做的事儿

* ###  音节分割

  * 参考文献复现了voice activity detection方法

  ![](https://s1.ax1x.com/2020/03/22/852hkR.md.png)

  ​	第一幅图是目标输入音频的fbank图像，第二幅图是根据算法计算出来的VAD分布图，值为1的地方为激活状态（有声音）。图三是过滤后的结果，也是最终结果

  * 用tensorflow复现了Focal Loss损失函数，并用于对音节边界判断的模型的训练

    虽然模型训练结果还算不错，但是分类实战结果不太理想

  * 将VAD方法融入我之前的模型，并对之前的模型进行了参数调整重新训练

    ![](https://s1.ax1x.com/2020/03/22/85v1tx.png)

    效果比想象中好

    展示结果解释：

    第一张图是输入音频的Fbank可视化结果

    第二张图中：

    ​	橘色是目标tag，每一个突起是一个音节，停顿部分用-0.5~0的随机数标记

    ​	绿色是直接的模型输出，可以看到还是之前的问题：silence检测不准确

    ​	蓝色的竖线方框，是VAD算法计算出来的声音有效位置

    ​	红色是绿色经过VAD计算过滤后的样子

    ​	蓝色是对红色进行平滑操作后的结果

    ​	蓝色中黑色的竖线则为最终结果：每个音节的边界，可以看到跟橘色的边界差别不大，效果已经能够接受

* ### 圆润度

  * 圆润度一般用来描述饱满度。谐波的分布，高次泛音越丰富 声音更圆润，所以我还是用Fbank直接进行训练模型
  * 最终均方误差为0.887   （最大值为7）
  * 以下是误差分布图
  * ![](https://s1.ax1x.com/2020/03/22/8ICKBD.png)


## 下周计划

- 将目前能够提取到的特征全部整合一下
- 利用整合的特征，去预测抽象类描述维度

## 想问的问题

- 无