# 全卷积网络

CNN的强大之处在于他的多层结构，并且可以学习到多个层次的特征：比较浅的卷积层感知域比较小，能够学习到一些局部区域的特征。较深的卷积层具有较大的感知域，能够学习到更加抽象的一些特征。抽象特征对物体的大小、位置和方向敏感性较低（卷积的抗翻转性），从而有助于识别性能的提高。这些抽象特征可以很好地判断出一幅图像中包含什么类的物体，但是因为丢失了一些物体的细节，所以不能很好地给出物体的**具体**轮廓、指出每个像素具体属于哪个物体，因此做到精确的分割就很有难度。

### FCN原理

FCN将传统CNN中的全连接层转换成一个个卷积层

![](https://img-blog.csdn.net/20160514044341551)

FCN将最后三层改为卷积层，卷积核大小为（4096，1，1），（4096，1，1），（1000，1，1）。故为全卷积层。

如果卷积的输出输入都只是一个平面，那么1x1卷积核并没有什么意义，它是完全不考虑像素与周边其他像素关系。

疑惑：1x1的卷积核的用处？->1、降维（ dimension reductionality ）。比如，一张500 * 500且厚度depth为100 的图片在20个filter上做1x1的卷积，那么结果的大小为500x500x20。2、加入非线性。卷积层之后经过激励层，1*1的卷积在前一层的学习表示上添加了非线性激励（ non-linear activation ），提升网络的表达能力；

